{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ea6bd6-02eb-402d-9795-1dab6cf5280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from xgboost import XGBRFClassifier\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b08622d-6c7a-46f7-bb8a-3090c708cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the minimum number of trials as a threshold number to accept an input feature as a selected feature\n",
    "def get_tail_items(pmf, significance_level=0.05):\n",
    "    # Set total to zero\n",
    "    total = 0\n",
    "    # Create a loop based on the probability mass function\n",
    "    for i, x in enumerate(pmf):\n",
    "        print(i,x)\n",
    "        # Increment the total variable\n",
    "        total += x\n",
    "        # If total is higher than the significance level\n",
    "        if total >= significance_level:\n",
    "            # Break the code\n",
    "            break\n",
    "    # Return i\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c21187-015c-4e91-a903-739f62a6adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features from n number of trials\n",
    "def choose_features(feature_hits, TRIALS, thresh):\n",
    "    # Define the  boundaries for the green zone\n",
    "    # Define the green zone threshold\n",
    "    green_zone_thresh = TRIALS - thresh\n",
    "    # Define the blue zone upper threshold\n",
    "    blue_zone_upper = green_zone_thresh\n",
    "    # Define the blue zone lower threshold\n",
    "    blue_zone_lower = thresh\n",
    "\n",
    "    # Select the input features as green whenever their hits are higher than the green zone threshold\n",
    "    green_zone = [key for key, value in feature_hits.items() if value >= green_zone_thresh]\n",
    "    # Select the input features as blue whenever their hits are between the blue zone lower threshold and the blue zone upper threshold  \n",
    "    blue_zone = [key for key, value in feature_hits.items() if (value >= blue_zone_lower and value < blue_zone_upper)]\n",
    "    return green_zone, blue_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28058e0e-7ba3-486a-8d86-9d622539d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boruta_shap_algorithm(X, y, trials=20, workers=2, significance_level=0.05, seed=2024):\n",
    "    # Set the seed\n",
    "    np.random.seed(seed)        \n",
    "\n",
    "    # Assert that the number of samples of both data match\n",
    "    assert X.shape[0] == y.shape[0], \"X and y dimensions don't coincide\"\n",
    "\n",
    "    # Set a dictionary to save the number of hits for each feature\n",
    "    features_hits = {feature:0 for feature in X.columns}\n",
    "\n",
    "    # Create the names of all the features shuffled\n",
    "    shuffled_col_names = [str(column+'_shuffle') for column in X.columns]\n",
    "\n",
    "    # Set the train and test X data\n",
    "    X_train, X_test = X.iloc[:int(0.8*len(X))], X.iloc[int(0.8*len(X)):]\n",
    "\n",
    "    # Set the label enconder object\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Transform the y series to a prediction features useful for the machine-learning model\n",
    "    label_encoded = le.fit_transform(y)\n",
    "\n",
    "    # Transform the encoded label into a Pandas series\n",
    "    y = pd.Series(data=label_encoded, index=y.index, name='y')\n",
    "\n",
    "    # Set the y train data\n",
    "    y_train = y.iloc[:int(0.8*len(y))]\n",
    "    \n",
    "    # define the model\n",
    "    classifier = XGBRFClassifier(n_estimators=100, subsample=1, colsample_bynode=1, tree_method='gpu_hist', random_state=seed)  \n",
    "\n",
    "    # Define a function to compute the number of times the features \n",
    "    def features_hits_func(trial):\n",
    "        # Set the seed for the trial\n",
    "        np.random.seed(seed+trial)\n",
    "\n",
    "        # Set the X train data for the shuffled features\n",
    "        X_shuffle_train = X_train.apply(np.random.permutation)\n",
    "        # Set the names for the X train shuffled features\n",
    "        X_shuffle_train.columns = shuffled_col_names\n",
    "        # Set the X-test data for the shuffled features\n",
    "        X_shuffle_test = X_test.apply(np.random.permutation)\n",
    "        # Set the names for the X-test shuffled features\n",
    "        X_shuffle_test.columns = shuffled_col_names\n",
    "\n",
    "        # Set the whole input features for the Boruta Shap algorithm training\n",
    "        X_boruta_train = pd.concat([X_train, X_shuffle_train], axis=1)\n",
    "        # Set the whole input features for the Boruta Shap algorithm test data\n",
    "        X_boruta_test = pd.concat([X_test, X_shuffle_test], axis=1)\n",
    "\n",
    "        # Fit the model\n",
    "        model = classifier.fit(X_boruta_train, y_train)\n",
    "\n",
    "        # Set the explainer object\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        # Get the Shap values for each feature\n",
    "        shap_values = explainer.shap_values(X_boruta_test)\n",
    "\n",
    "        # Set the mean value of each feature's Shap values\n",
    "        features_importance = np.array(np.abs(shap_values).mean(0))\n",
    "        # Set a dataframe with the above features' importance\n",
    "        features_importance_df = pd.DataFrame(data=features_importance, index=X_boruta_test.columns, columns=['Values'])\n",
    "\n",
    "        # Subset the feature importance dataframe with the non-shuffled features\n",
    "        feature_imp_X = features_importance_df.iloc[:len(X.columns)]\n",
    "        # Subset the feature importance dataframe with the shuffled features\n",
    "        feature_imp_shuffled = features_importance_df.iloc[len(X.columns):]\n",
    "\n",
    "        # Add one hit in case the feature is better than the best Shap value of all the shuffled features\n",
    "        for feature in feature_imp_X.index:\n",
    "            features_hits[feature] += int(feature_imp_X.loc[feature,'Values'] > feature_imp_shuffled['Values'].max())\n",
    "\n",
    "    # Define a function to run multiple trials as per the maximum number of cores available in your CPU\n",
    "    def multithreading_loop(function, params_list):\n",
    "        # Set the number of lists we'll have as per the number of cores\n",
    "        num_lists = int(np.floor(len(params_list)/workers))\n",
    "        # Set the params list to be used to loop \n",
    "        params_list_for_loop = params_list[:int(num_lists*workers)]\n",
    "        # If the number of trials in the above list is higher than the num_lists\n",
    "        if len(params_list)>int(num_lists*workers):\n",
    "            # Create the last params list to be used to multithread the computations\n",
    "            last_params_list = params_list[int(num_lists*workers):]\n",
    "\n",
    "        # For each list of trials\n",
    "        for i in range(0,num_lists):\n",
    "            # Use the number of cores for the futures library executor\n",
    "            with futures.ThreadPoolExecutor(workers) as executor:\n",
    "                # Run the features_hits_func function to compute the hits in parallel\n",
    "                list(executor.map(function, params_list_for_loop[int(workers*i):int(workers*(i+1))]))\n",
    "        # Once you finish the above, run the last trials to be computed in parallel\n",
    "        if len(params_list)>int(num_lists*workers):\n",
    "            # Use the number of cores for the futures library executor \n",
    "            with futures.ThreadPoolExecutor(len(last_params_list)) as executor:\n",
    "                # Run the features_hits_func function to compute the hits in parallel\n",
    "                list(executor.map(function, last_params_list)) \n",
    "\n",
    "    # Set the range for the number of trails as a list\n",
    "    trails_list = [*range(trials)]\n",
    "\n",
    "    # Run the loop to compute the trails in parallel in buckets\n",
    "    multithreading_loop(features_hits_func, trails_list)      \n",
    "    \n",
    "    # Calculate the probability mass function: Get the Binomial distribution in \"trials\" number of buckets\n",
    "    pmf = [sp.stats.binom.pmf(x, trials, .5) for x in range(trials + 1)]\n",
    "\n",
    "    # Set the minimum number of trials as the threshold to classify an input feature as a selected feature\n",
    "    thresh = get_tail_items(pmf, significance_level)\n",
    "    \n",
    "    # green are the accepted features, blue are the tentative features\n",
    "    green, blue = choose_features(features_hits, trials, thresh)\n",
    "\n",
    "    # If there are green features\n",
    "    if len(green) != 0:\n",
    "        # Return the green features\n",
    "        return green\n",
    "    # If there aren't green features\n",
    "    else:\n",
    "        # If there are blue features\n",
    "        if len(blue) != 0:\n",
    "            # Return the blue features\n",
    "            return blue\n",
    "        # If there aren't blue features\n",
    "        else:\n",
    "            # Return all the features\n",
    "            return X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121a4963-49bd-4307-bf82-fee6b7eb2a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2.980232238769538e-08),\n",
       " (1, 7.450580596923815e-07),\n",
       " (2, 8.94069671630861e-06),\n",
       " (3, 6.85453414916993e-05),\n",
       " (4, 0.000376999378204346),\n",
       " (5, 0.0015833973884582507),\n",
       " (6, 0.005277991294860841),\n",
       " (7, 0.01432597637176514),\n",
       " (8, 0.03223344683647155),\n",
       " (9, 0.06088539958000171),\n",
       " (10, 0.09741663932800292),\n",
       " (11, 0.13284087181091325),\n",
       " (12, 0.15498101711273188),\n",
       " (13, 0.15498101711273188),\n",
       " (14, 0.13284087181091325),\n",
       " (15, 0.09741663932800294),\n",
       " (16, 0.06088539958000171),\n",
       " (17, 0.03223344683647156),\n",
       " (18, 0.014325976371765138),\n",
       " (19, 0.00527799129486084),\n",
       " (20, 0.0015833973884582509),\n",
       " (21, 0.000376999378204346),\n",
       " (22, 6.854534149169929e-05),\n",
       " (23, 8.94069671630861e-06),\n",
       " (24, 7.450580596923813e-07),\n",
       " (25, 2.9802322387695312e-08)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from xgboost import XGBRFClassifier\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent import futures\n",
    "\n",
    "# Set the minimum number of trials as a threshold number to accept an input feature as a selected feature\n",
    "def get_tail_items(pmf, significance_level=0.05):\n",
    "    # Set total to zero\n",
    "    total = 0\n",
    "    # Create a loop based on the probability mass function\n",
    "    for i, x in enumerate(pmf):\n",
    "        print(i,x)\n",
    "        # Increment the total variable\n",
    "        total += x\n",
    "        # If total is higher than the significance level\n",
    "        if total >= significance_level:\n",
    "            # Break the code\n",
    "            break\n",
    "    # Return i\n",
    "    return I\n",
    "\n",
    "# select features from n number of trials\n",
    "def choose_features(feature_hits, TRIALS, thresh):\n",
    "    # Define the  boundaries for the green zone\n",
    "    # Define the green zone threshold\n",
    "    green_zone_thresh = TRIALS - thresh\n",
    "    # Define the blue zone upper threshold\n",
    "    blue_zone_upper = green_zone_thresh\n",
    "    # Define the blue zone lower threshold\n",
    "    blue_zone_lower = thresh\n",
    "\n",
    "    # Select the input features as green whenever their hits are higher than the green zone threshold\n",
    "    green_zone = [key for key, value in feature_hits.items() if value >= green_zone_thresh]\n",
    "    # Select the input features as blue whenever their hits are between the blue zone lower threshold and the blue zone upper threshold  \n",
    "    blue_zone = [key for key, value in feature_hits.items() if (value >= blue_zone_lower and value < blue_zone_upper)]\n",
    "    return green_zone, blue_zone\n",
    "\n",
    "def boruta_shap_algorithm(X, y, trials=20, workers=2, significance_level=0.05, seed=2024):\n",
    "    # Set the seed\n",
    "    np.random.seed(seed)        \n",
    "\n",
    "    # Assert that the number of samples of both data match\n",
    "    assert X.shape[0] == y.shape[0], \"X and y dimensions don't coincide\"\n",
    "\n",
    "    # Set a dictionary to save the number of hits for each feature\n",
    "    features_hits = {feature:0 for feature in X.columns}\n",
    "\n",
    "    # Create the names of all the features shuffled\n",
    "    shuffled_col_names = [str(column+'_shuffle') for column in X.columns]\n",
    "\n",
    "    # Set the train and test X data\n",
    "    X_train, X_test = X.iloc[:int(0.8*len(X))], X.iloc[int(0.8*len(X)):]\n",
    "\n",
    "    # Set the label enconder object\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Transform the y series to a prediction features useful for the machine-learning model\n",
    "    label_encoded = le.fit_transform(y)\n",
    "\n",
    "    # Transform the encoded label into a Pandas series\n",
    "    y = pd.Series(data=label_encoded, index=y.index, name='y')\n",
    "\n",
    "    # Set the y train data\n",
    "    y_train = y.iloc[:int(0.8*len(y))]\n",
    "    \n",
    "    # define the model\n",
    "    classifier = XGBRFClassifier(n_estimators=100, subsample=1, colsample_bynode=1, tree_method='gpu_hist', random_state=seed)  \n",
    "\n",
    "    # Define a function to compute the number of times the features \n",
    "    def features_hits_func(trial):\n",
    "        # Set the seed for the trial\n",
    "        np.random.seed(seed+trial)\n",
    "\n",
    "        # Set the X train data for the shuffled features\n",
    "        X_shuffle_train = X_train.apply(np.random.permutation)\n",
    "        # Set the names for the X train shuffled features\n",
    "        X_shuffle_train.columns = shuffled_col_names\n",
    "        # Set the X-test data for the shuffled features\n",
    "        X_shuffle_test = X_test.apply(np.random.permutation)\n",
    "        # Set the names for the X-test shuffled features\n",
    "        X_shuffle_test.columns = shuffled_col_names\n",
    "\n",
    "        # Set the whole input features for the Boruta Shap algorithm training\n",
    "        X_boruta_train = pd.concat([X_train, X_shuffle_train], axis=1)\n",
    "        # Set the whole input features for the Boruta Shap algorithm test data\n",
    "        X_boruta_test = pd.concat([X_test, X_shuffle_test], axis=1)\n",
    "\n",
    "        # Fit the model\n",
    "        model = classifier.fit(X_boruta_train, y_train)\n",
    "\n",
    "        # Set the explainer object\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        # Get the Shap values for each feature\n",
    "        shap_values = explainer.shap_values(X_boruta_test)\n",
    "\n",
    "        # Set the mean value of each feature's Shap values\n",
    "        features_importance = np.array(np.abs(shap_values).mean(0))\n",
    "        # Set a dataframe with the above features' importance\n",
    "        features_importance_df = pd.DataFrame(data=features_importance, index=X_boruta_test.columns, columns=['Values'])\n",
    "\n",
    "        # Subset the feature importance dataframe with the non-shuffled features\n",
    "        feature_imp_X = features_importance_df.iloc[:len(X.columns)]\n",
    "        # Subset the feature importance dataframe with the shuffled features\n",
    "        feature_imp_shuffled = features_importance_df.iloc[len(X.columns):]\n",
    "\n",
    "        # Add one hit in case the feature is better than the best Shap value of all the shuffled features\n",
    "        for feature in feature_imp_X.index:\n",
    "            features_hits[feature] += int(feature_imp_X.loc[feature,'Values'] > feature_imp_shuffled['Values'].max())\n",
    "\n",
    "    # Define a function to run multiple trials as per the maximum number of cores available in your CPU\n",
    "    def multithreading_loop(function, params_list):\n",
    "        # Set the number of lists we'll have as per the number of cores\n",
    "        num_lists = int(np.floor(len(params_list)/workers))\n",
    "        # Set the params list to be used to loop \n",
    "        params_list_for_loop = params_list[:int(num_lists*workers)]\n",
    "        # If the number of trials in the above list is higher than the num_lists\n",
    "        if len(params_list)>int(num_lists*workers):\n",
    "            # Create the last params list to be used to multithread the computations\n",
    "            last_params_list = params_list[int(num_lists*workers):]\n",
    "\n",
    "        # For each list of trials\n",
    "        for i in range(0,num_lists):\n",
    "            # Use the number of cores for the futures library executor\n",
    "            with futures.ThreadPoolExecutor(workers) as executor:\n",
    "                # Run the features_hits_func function to compute the hits in parallel\n",
    "                list(executor.map(function, params_list_for_loop[int(workers*i):int(workers*(i+1))]))\n",
    "        # Once you finish the above, run the last trials to be computed in parallel\n",
    "        if len(params_list)>int(num_lists*workers):\n",
    "            # Use the number of cores for the futures library executor \n",
    "            with futures.ThreadPoolExecutor(len(last_params_list)) as executor:\n",
    "                # Run the features_hits_func function to compute the hits in parallel\n",
    "                list(executor.map(function, last_params_list)) \n",
    "\n",
    "    # Set the range for the number of trails as a list\n",
    "    trails_list = [*range(trials)]\n",
    "\n",
    "    # Run the loop to compute the trails in parallel in buckets\n",
    "    multithreading_loop(features_hits_func, trails_list)      \n",
    "    \n",
    "    # Calculate the probability mass function: Get the Binomial distribution in \"trials\" number of buckets\n",
    "    pmf = [sp.stats.binom.pmf(x, trials, .5) for x in range(trials + 1)]\n",
    "\n",
    "    # Set the minimum number of trials as the threshold to classify an input feature as a selected feature\n",
    "    thresh = get_tail_items(pmf, significance_level)\n",
    "    \n",
    "    # green are the accepted features, blue are the tentative features\n",
    "    green, blue = choose_features(features_hits, trials, thresh)\n",
    "\n",
    "    # If there are green features\n",
    "    if len(green) != 0:\n",
    "        # Return the green features\n",
    "        return green\n",
    "    # If there aren't green features\n",
    "    else:\n",
    "        # If there are blue features\n",
    "        if len(blue) != 0:\n",
    "            # Return the blue features\n",
    "            return blue\n",
    "        # If there aren't blue features\n",
    "        else:\n",
    "            # Return all the features\n",
    "            return X.columns.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
